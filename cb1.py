
# rag_streamlit_chatbot.py

import os
import streamlit as st
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain_groq import ChatGroq

# === CONFIG ===
os.environ["Groq-img"] = "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"  # üîë ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ

st.set_page_config(page_title="üìÑ RAG Chatbot from PDF", page_icon="ü§ñ")

st.title("üìÑü§ñ RAG Chatbot from PDF (Groq + LLaMA3)")
st.markdown("‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå PDF ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ RAG ‡πÅ‡∏•‡∏∞ LLaMA3 ‡∏à‡∏≤‡∏Å Groq")

uploaded_file = st.file_uploader("üì§ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î PDF", type="pdf")

if uploaded_file is not None:
    with st.spinner("üìö ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£..."):
        # === Step 1: Load PDF ===
        with open("temp_uploaded.pdf", "wb") as f:
            f.write(uploaded_file.read())

        loader = PyPDFLoader("temp_uploaded.pdf")
        pages = loader.load()

        # === Step 2: Split Document ===
        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
        chunks = splitter.split_documents(pages)

        # === Step 3: Embed & Store ===
        embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
        vectorstore = FAISS.from_documents(chunks, embeddings)

        # === Step 4: Set up Groq + RetrievalQA ===
        llm = ChatGroq(model_name="llama3-70b-8192", temperature=0)
        rag_chain = RetrievalQA.from_chain_type(
            llm=llm,
            retriever=vectorstore.as_retriever(),
            return_source_documents=True
        )

        st.success("‚úÖ ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ñ‡∏π‡∏Å‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏ù‡∏±‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß!")

        # === Step 5: Chat Interface ===
        if "chat_history" not in st.session_state:
            st.session_state.chat_history = []

        user_question = st.text_area("‚úçÔ∏è ‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£")

        if st.button("‡∏ñ‡∏≤‡∏°"):
            if user_question.strip() != "":
                with st.spinner("ü§ñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏ï‡∏≠‡∏ö..."):
                    result = rag_chain.invoke({"query": user_question})
                    answer = result["result"]

                    st.session_state.chat_history.append(("‡∏Ñ‡∏∏‡∏ì", user_question))
                    st.session_state.chat_history.append(("Bot", answer))

        # Show chat history
        for sender, message in reversed(st.session_state.chat_history):
            st.markdown(f"**{sender}:** {message}")
else:
    st.info("üìå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå PDF ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô")
